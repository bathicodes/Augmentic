{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data pre-processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPK+hzI5SHpje8yoJ9zcs5C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bathicodes/Augmentic/blob/main/Data_pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "5q8ETV09RA4m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "rxUeqbl6Q7xa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import dataset"
      ],
      "metadata": {
        "id": "TayOAvFmST1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Data.csv')\n",
        "x = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "9AoOfYnFSVwy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take care of missing data"
      ],
      "metadata": {
        "id": "dLbXmkLjSxiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(x[:, 1:3])\n",
        "x[:, 1:3] = imputer.transform(x[:, 1:3])"
      ],
      "metadata": {
        "id": "LPG7CxFeS0aT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode categorical data"
      ],
      "metadata": {
        "id": "efpK28VedAfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encode the independent varibales"
      ],
      "metadata": {
        "id": "ssitn9XdgOKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct = ColumnTransformer(transformers=[('encode', OneHotEncoder(),[0])], remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))"
      ],
      "metadata": {
        "id": "jzIKQu1LdDn_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encode the dependent variable"
      ],
      "metadata": {
        "id": "dBLnb14agTj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "EVi8vm60gcRO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split dataset into training and testing set"
      ],
      "metadata": {
        "id": "86TmWPZqk4xJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "9x0m7XDVk8s2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_AhTAi_tP3l",
        "outputId": "ce530518-eac6-477b-9221-32daacd935d1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 37.0 67000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature scaling\n",
        "\n",
        "First we scale the features of the training set and then scale up the testing set features by transforming the training set mean and standard diviation. We are only use **transform** method to scale testing set."
      ],
      "metadata": {
        "id": "rCaVuio3mDK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train[:,3:] = sc.fit(x_train[:,3:]) \n",
        "x_test[:, 3:] = sc.transform(x_test[:,3:])"
      ],
      "metadata": {
        "id": "gm_M4vJ-mFeh"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}